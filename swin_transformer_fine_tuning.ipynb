{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "41784d341075454ca1542c03088f3014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_5033d5fe61a047de997f2b63474efa5d"
          }
        },
        "22acd3b9ba3247f59100db06f82e1c3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a191a4ae850341708e575a151b5de83f",
            "placeholder": "​",
            "style": "IPY_MODEL_5d060f27645c40a6b8c72894ef3a7a16",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "7bf490b0acde431c84f1c951516691cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_482965d6737945a0b0e1726a7ac58ed0",
            "placeholder": "​",
            "style": "IPY_MODEL_556c6dd7de504b879ea95179fa81603e",
            "value": ""
          }
        },
        "f6f106d13c1942bdbc3e93159f3a709e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_e70c97360e924755bc425d2a9658f2aa",
            "style": "IPY_MODEL_74954903e5584f7b98a9df6f4e1b55a9",
            "value": false
          }
        },
        "be96c73cb9d346d091d63734988cb92f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_03fe8f5b32f84fa986530cd232fc6920",
            "style": "IPY_MODEL_3c8cd0389e8740688a6e5f357f9050df",
            "tooltip": ""
          }
        },
        "6eb5f398c7834428a4c5207f01b6c565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3eeed8435f944ab09c9f296267e13e90",
            "placeholder": "​",
            "style": "IPY_MODEL_bfaa578c7dad4f549e12894ce3084dd5",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "5033d5fe61a047de997f2b63474efa5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "a191a4ae850341708e575a151b5de83f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d060f27645c40a6b8c72894ef3a7a16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "482965d6737945a0b0e1726a7ac58ed0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "556c6dd7de504b879ea95179fa81603e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e70c97360e924755bc425d2a9658f2aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74954903e5584f7b98a9df6f4e1b55a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03fe8f5b32f84fa986530cd232fc6920": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c8cd0389e8740688a6e5f357f9050df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "3eeed8435f944ab09c9f296267e13e90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfaa578c7dad4f549e12894ce3084dd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a39fb2ee46ba4e9891a68dbc662d70e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4036c6cba5d44a869b4f58d86ed02c03",
            "placeholder": "​",
            "style": "IPY_MODEL_3665210b7ac8484598567bf903f1919f",
            "value": "Connecting..."
          }
        },
        "4036c6cba5d44a869b4f58d86ed02c03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3665210b7ac8484598567bf903f1919f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12d61426fb4747fb9e522d40dccb71da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a4d0d1fb5c14b0ebb37cf454f1d1295",
              "IPY_MODEL_a6e49a77d68e4f3ab6fbd546b21e6c3e",
              "IPY_MODEL_efe384fd06f64fc09f94f879deb6a2c4"
            ],
            "layout": "IPY_MODEL_7d6a0c68a5c848b18bbf49e7985f1f14"
          }
        },
        "8a4d0d1fb5c14b0ebb37cf454f1d1295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19f6531d954f413ab44df5930be289a6",
            "placeholder": "​",
            "style": "IPY_MODEL_d28c8b7780b64834943d830a991bbf58",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "a6e49a77d68e4f3ab6fbd546b21e6c3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0df4c20b03d04a959f4c4078a992929e",
            "max": 255,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e531c73ebfa645faa179fd1ff4ce7f68",
            "value": 255
          }
        },
        "efe384fd06f64fc09f94f879deb6a2c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bd8dd96df93494eac19ad9d7caf5895",
            "placeholder": "​",
            "style": "IPY_MODEL_835787c941ae430e8fdb802844aba1ef",
            "value": " 255/255 [00:00&lt;00:00, 33.2kB/s]"
          }
        },
        "7d6a0c68a5c848b18bbf49e7985f1f14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19f6531d954f413ab44df5930be289a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d28c8b7780b64834943d830a991bbf58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0df4c20b03d04a959f4c4078a992929e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e531c73ebfa645faa179fd1ff4ce7f68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7bd8dd96df93494eac19ad9d7caf5895": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "835787c941ae430e8fdb802844aba1ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# References"
      ],
      "metadata": {
        "id": "0JGdk3Itd6mC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hugging Face - Documentation [online]. Huggingface.co. Available from: https://huggingface.co/docs.\n",
        "\n",
        "PyTorch Foundation [online]. PyTorch. Available from: https://pytorch.org/."
      ],
      "metadata": {
        "id": "CvlHZIeod9AR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <i> Huggingface Login </i>"
      ],
      "metadata": {
        "id": "iO6yIHhpymMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "from google.colab import userdata\n",
        "\n",
        "notebook_login(userdata.get('HF_TOKEN'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73,
          "referenced_widgets": [
            "41784d341075454ca1542c03088f3014",
            "22acd3b9ba3247f59100db06f82e1c3b",
            "7bf490b0acde431c84f1c951516691cd",
            "f6f106d13c1942bdbc3e93159f3a709e",
            "be96c73cb9d346d091d63734988cb92f",
            "6eb5f398c7834428a4c5207f01b6c565",
            "5033d5fe61a047de997f2b63474efa5d",
            "a191a4ae850341708e575a151b5de83f",
            "5d060f27645c40a6b8c72894ef3a7a16",
            "482965d6737945a0b0e1726a7ac58ed0",
            "556c6dd7de504b879ea95179fa81603e",
            "e70c97360e924755bc425d2a9658f2aa",
            "74954903e5584f7b98a9df6f4e1b55a9",
            "03fe8f5b32f84fa986530cd232fc6920",
            "3c8cd0389e8740688a6e5f357f9050df",
            "3eeed8435f944ab09c9f296267e13e90",
            "bfaa578c7dad4f549e12894ce3084dd5",
            "a39fb2ee46ba4e9891a68dbc662d70e6",
            "4036c6cba5d44a869b4f58d86ed02c03",
            "3665210b7ac8484598567bf903f1919f"
          ]
        },
        "id": "fSZkK-i9ye0H",
        "outputId": "8665c0e8-de22-421e-face-e80276659be0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:38: FutureWarning: Deprecated positional argument(s) used in 'notebook_login': pass new_session='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' as keyword args. From version 1.0 passing these as positional arguments will result in an error,\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41784d341075454ca1542c03088f3014"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "EszrACwHzAkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tuning Swin Transformer on IU X-Ray dataset (image-text contrastive learning)\n",
        "import os\n",
        "import json\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.optim import AdamW\n",
        "from torchvision.transforms import v2\n",
        "from transformers import (\n",
        "    AutoModel,\n",
        "    AutoTokenizer,\n",
        "    AutoImageProcessor,\n",
        "    AutoFeatureExtractor,\n",
        "    VisionTextDualEncoderModel,\n",
        "    VisionTextDualEncoderProcessor,\n",
        "    EarlyStoppingCallback,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")"
      ],
      "metadata": {
        "id": "RHKbvqxr8E44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Handler"
      ],
      "metadata": {
        "id": "YW1v3QffzDl7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kh7La3ICZQvw"
      },
      "outputs": [],
      "source": [
        "# Step 3: Create a PyTorch Dataset to yield image pixels and tokenized text\n",
        "class IUXRayDataset(Dataset):\n",
        "    def __init__(self, image_paths, texts, tokenizer, image_processor, transforms, max_length=256):\n",
        "        self.image_paths = image_paths\n",
        "        self.texts = texts\n",
        "        self.tokenizer = tokenizer\n",
        "        self.image_processor = image_processor\n",
        "        self.max_length = max_length\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load image and its corresponding report\n",
        "        text = self.texts[idx]\n",
        "        img_path = text['image_path'][1]\n",
        "        img_path = os.path.join(self.image_paths, img_path)\n",
        "        report = text.get(\"report\", \"\")\n",
        "        # Open the X-ray image and convert grayscale to RGB\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        # Preprocess image (resize to 224x224, normalize) and get pixel tensor\n",
        "        image = self.transforms(image)\n",
        "        pixel_tensor = self.image_processor(image, return_tensors=\"pt\")[\"pixel_values\"].squeeze(0)\n",
        "        # Normalize data between 0 and 1\n",
        "        scaled_data  = (pixel_tensor - pixel_tensor.min()) / (pixel_tensor.max() - pixel_tensor.min())\n",
        "        # Tokenize the report text (BERT tokenizer) without padding (we will pad in the collator)\n",
        "        encoding = self.tokenizer(report, max_length=self.max_length, truncation=True, padding=False)\n",
        "        input_ids = encoding[\"input_ids\"]\n",
        "        attention_mask = encoding[\"attention_mask\"]\n",
        "        return {\"pixel_values\": scaled_data, \"input_ids\": input_ids, \"attention_mask\": attention_mask}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Image path\n",
        "image_paths = \"/content/drive/MyDrive/iu_xray/images\"\n",
        "# Report path\n",
        "report_path = '/content/drive/MyDrive/iu_xray/annotation.json'\n",
        "texts = json.load(open(report_path, 'r'))\n",
        "\n",
        "# Preprocess images\n",
        "transforms = v2.Compose([\n",
        "    v2.ToImage(),\n",
        "    v2.Resize((224, 224)),\n",
        "    v2.RandomHorizontalFlip(p=0.5),\n",
        "    v2.RandomRotation(degrees=(-10, 10)),\n",
        "    v2.ToTensor()\n",
        "])\n",
        "\n",
        "# Step 2: Initialize the tokenizer and image processor for the encoders\n",
        "text_model_name = \"microsoft/BiomedVLP-CXR-BERT-general\"   # BERT-style text encoder for radiology reports\n",
        "# vision_model_name = \"microsoft/swin-tiny-patch4-window7-224\"  # Swin Transformer visual encoder (224x224 input)\n",
        "vision_model_name = \"facebook/maskformer-swin-base-coco\"\n",
        "cache_dir = '/content/huggingface'\n",
        "tokenizer = AutoTokenizer.from_pretrained(text_model_name, cache_dir=cache_dir)\n",
        "# The image processor will convert images to RGB, resize to Swin's expected size, and normalize pixel values.\n",
        "image_processor = AutoImageProcessor.from_pretrained(vision_model_name, cache_dir=cache_dir)\n",
        "# Combine into a single processor (for convenience in saving/loading later)\n",
        "processor = VisionTextDualEncoderProcessor(image_processor=image_processor, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "X8Tj7uydTZV_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af61658f-9ce1-4352-c710-c030dda4b092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/deprecation.py:172: FutureWarning: `max_size` is deprecated and removed starting from version 4.27.0 for `MaskFormerImageProcessor.__init__`.\n",
            "  return func(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "0bwM6Te0k3ul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the training and validation datasets\n",
        "test_len_half = int(len(texts['test'])/2)\n",
        "train_reports = texts['train']+texts['test'][:test_len_half]\n",
        "val_reports   = texts['val']+texts['test'][test_len_half:]\n",
        "train_dataset = IUXRayDataset(image_paths, train_reports, tokenizer, image_processor, transforms)\n",
        "val_dataset   = IUXRayDataset(image_paths, val_reports, tokenizer, image_processor, transforms)"
      ],
      "metadata": {
        "id": "o2iIn6LjTDI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset), len(val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKpOXDuGgon1",
        "outputId": "589e36f2-077c-43bb-c6f8-fd5fa8398976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2364, 591)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset) / (len(train_dataset) + len(val_dataset)) * 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WK2vJNW152SE",
        "outputId": "eb4bffa5-8344-4dd8-b4e0-0e5000e44e8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80.0"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "oRPJ1aboXHnF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Facebook Swin Transformer"
      ],
      "metadata": {
        "id": "u7kfPa7pYoH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SwinWithPooling(nn.Module):\n",
        "    def __init__(self, model_name):\n",
        "        super().__init__()\n",
        "        # Load the Swin backbone\n",
        "        self.vision_model = AutoModel.from_pretrained(model_name)\n",
        "        self.config = self.vision_model.config\n",
        "\n",
        "    def forward(self, pixel_values):\n",
        "        outputs = self.vision_model(pixel_values)\n",
        "        last_hidden_state = outputs.last_hidden_state  # shape: [batch_size, num_patches, hidden_dim]\n",
        "\n",
        "        # Apply mean pooling across spatial tokens\n",
        "        pooled = last_hidden_state.mean(dim=1)  # shape: [batch_size, hidden_dim]\n",
        "\n",
        "        return pooled"
      ],
      "metadata": {
        "id": "mfz5jSXlWrb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize your text and vision encoders\n",
        "vision_encoder = SwinWithPooling(vision_model_name)\n",
        "text_encoder = AutoModel.from_pretrained(text_model_name)\n",
        "\n",
        "# Wrap them into a dual encoder\n",
        "dual_model = VisionTextDualEncoderModel(vision_model=vision_encoder, text_model=text_encoder)"
      ],
      "metadata": {
        "id": "6SjDTA1bXDDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dual_model.logit_scale.requires_grad_(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvgaBetFYFV9",
        "outputId": "81dfc2d2-3194-431e-fb0e-bb876121ba90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor(2.6592, requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List all vision (Swin) encoder parameters and their requires_grad status\n",
        "for name, param in dual_model.vision_model.named_parameters():\n",
        "    print(name, param.requires_grad)\n",
        "    break\n",
        "\n",
        "# List all text (BERT) encoder parameters and their requires_grad status\n",
        "for name, param in dual_model.text_model.named_parameters():\n",
        "    print(name, param.requires_grad)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5haU9o-FYLPs",
        "outputId": "1228bab3-01e6-4e75-fe1d-b6e6f1127631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vision_model.pixel_level_module.encoder.model.embeddings.patch_embeddings.projection.weight True\n",
            "embeddings.word_embeddings.weight True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Microsoft Swin Transformer"
      ],
      "metadata": {
        "id": "CjzgYQg_YXpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Initialize the VisionTextDualEncoderModel (Swin visual encoder + BERT text encoder)\n",
        "# This will load the two pretrained models and initialize projection layers for contrastive learning&#8203;:contentReference[oaicite:0]{index=0}.\n",
        "model = VisionTextDualEncoderModel.from_vision_text_pretrained(vision_model_name, text_model_name, cache_dir=cache_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KeIJljJW-gh",
        "outputId": "6d59d78a-ce0b-4d7c-efea-f8dfa8b712e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The projection layer and logit scale weights `['visual_projection.weight', 'text_projection.weight', 'logit_scale']` are newly initialized. You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure temperature (logit_scale) is trainable: it should be an nn.Parameter. We explicitly set requires_grad to True.\n",
        "model.logit_scale.requires_grad_(True)\n",
        "# (The logit_scale is a learnable scalar that scales the similarity logits in contrastive loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cux6YKc6VxV4",
        "outputId": "09be09cd-da3c-4782-e720-fb4ae3258a6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor(2.6592, requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List all vision (Swin) encoder parameters and their requires_grad status\n",
        "for name, param in model.vision_model.named_parameters():\n",
        "    print(name, param.requires_grad)\n",
        "    break\n",
        "\n",
        "# List all text (BERT) encoder parameters and their requires_grad status\n",
        "for name, param in model.text_model.named_parameters():\n",
        "    print(name, param.requires_grad)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9Ubl1gYnWjh",
        "outputId": "4b162c77-611d-4277-d04c-10bf1f71a2d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings.patch_embeddings.projection.weight True\n",
            "embeddings.word_embeddings.weight True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Contrastive Trainer"
      ],
      "metadata": {
        "id": "69RtV4JkYgO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ContrastiveTrainer(Trainer):\n",
        "    def compute_loss(self,\n",
        "                     model,\n",
        "                     inputs,\n",
        "                     return_outputs=False,\n",
        "                     num_items_in_batch=None):\n",
        "        outputs = model(**inputs, return_loss=True)\n",
        "        loss = outputs.loss\n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "FfN62EgQXGZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ContrastiveTrainer(Trainer):\n",
        "    def __init__(self, *args, temperature=0.07, log_cosine_sim=False, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.temperature = nn.Parameter(torch.tensor(temperature))\n",
        "        self.log_cosine_sim = log_cosine_sim\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        # Get image and text embeddings\n",
        "        image_embeds = outputs.image_embeds  # shape: [B, D]\n",
        "        text_embeds = outputs.text_embeds    # shape: [B, D]\n",
        "\n",
        "        # Normalize embeddings\n",
        "        image_embeds = F.normalize(image_embeds, p=2, dim=-1)\n",
        "        text_embeds = F.normalize(text_embeds, p=2, dim=-1)\n",
        "\n",
        "        # Compute cosine similarity (dot product of normalized vectors)\n",
        "        logits_per_image = torch.matmul(image_embeds, text_embeds.T) / self.temperature\n",
        "        logits_per_text = logits_per_image.T\n",
        "\n",
        "        # Contrastive loss (InfoNCE)\n",
        "        batch_size = image_embeds.size(0)\n",
        "        labels = torch.arange(batch_size, device=self.args.device)\n",
        "        loss_i2t = F.cross_entropy(logits_per_image, labels)\n",
        "        loss_t2i = F.cross_entropy(logits_per_text, labels)\n",
        "        loss = (loss_i2t + loss_t2i) / 2\n",
        "\n",
        "        # Optional: log cosine similarity between matched pairs\n",
        "        if self.log_cosine_sim and self.state.global_step % 50 == 0:\n",
        "            avg_cos_sim = F.cosine_similarity(image_embeds, text_embeds, dim=-1).mean().item()\n",
        "            self.log({'avg_cosine_similarity': avg_cos_sim})\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "k-B2dLu6gvou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data collector"
      ],
      "metadata": {
        "id": "ijqOuN5oXMBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Define a custom data collator to batch samples (pads text to the same length in a batch)\n",
        "def collate_fn(batch):\n",
        "    # Stack image pixel tensors (they are all 3x224x224 after processing)\n",
        "    # pixel_values = torch.stack([item[\"pixel_values\"] for item in batch])\n",
        "    pixel_values = torch.stack([item[\"pixel_values\"] for item in batch], dim=0)\n",
        "    # Pad the variable-length text sequences in the batch\n",
        "    input_ids_batch = [item[\"input_ids\"] for item in batch]\n",
        "    attention_mask_batch = [item[\"attention_mask\"] for item in batch]\n",
        "    padded = tokenizer.pad(\n",
        "        {\"input_ids\": input_ids_batch, \"attention_mask\": attention_mask_batch},\n",
        "        padding=True, return_tensors=\"pt\"\n",
        "    )\n",
        "    return {\n",
        "        \"pixel_values\": pixel_values,\n",
        "        \"input_ids\": padded[\"input_ids\"],\n",
        "        \"attention_mask\": padded[\"attention_mask\"]\n",
        "    }"
      ],
      "metadata": {
        "id": "OPSNHkLMXPvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainer"
      ],
      "metadata": {
        "id": "C281xCArXcfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Set up TrainingArguments with best practices (AdamW optimizer, 5e-5 LR, batch size 8, 5-8 epochs, etc.)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./iu_xray_swin_bert\",         # output directory for model checkpoints\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=20,                      # train for 20 epochs (adjustable up to ~8)\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=4,            # accumulate gradients over 4 steps\n",
        "    learning_rate=1e-5,\n",
        "    # learning_rate=1e-6,\n",
        "    weight_decay=0.01,                        # AdamW weight decay\n",
        "    # warmup_steps=500,                         # warmup for learning rate scheduler\n",
        "    warmup_ratio=0.1,                         # use 10% of training steps as warmup steps\n",
        "    eval_strategy=\"epoch\",                    # evaluate at end of each epoch\n",
        "    save_strategy=\"epoch\",                    # save checkpoint at end of each epoch\n",
        "    save_total_limit=1,                       # only keep the latest checkpoint (or best, since we load_best_model_at_end)\n",
        "    load_best_model_at_end=True,              # load best model (according to metric_for_best_model) at end of training\n",
        "    metric_for_best_model=\"eval_loss\",        # use validation loss to determine the best model\n",
        "    logging_steps=50,                         # log training metrics every 50 steps\n",
        "    remove_unused_columns=False,              # needed for multi-modal inputs (so Trainer doesn't drop image pixel_values)\n",
        "    fp16=True,                                # mixed precision for speed (set False if not using GPU with FP16)\n",
        "    greater_is_better=False,                  # lower eval_loss is better\n",
        "    optim=\"adamw_torch\",                      # use AdamW optimizer (Torch implementation)\n",
        "    lr_scheduler_type=\"reduce_lr_on_plateau\", # use ReduceLROnPlateau scheduler for dynamic LR\n",
        "    # lr_scheduler_type=\"linear\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_dir=\"./logs\",                     # directory for TensorBoard logs\n",
        "    report_to=\"tensorboard\"                   # enable logging to TensorBoard (optional: use \"wandb\" for Weights & Biases)\n",
        ")\n",
        "\n",
        "\n",
        "# EarlyStoppingCallback with patience of 3 epochs (will stop after 3 cons3ecutive epochs with no improvement in eval_loss)\n",
        "early_stop_callback = EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.0)\n",
        "\n",
        "\n",
        "trainer = ContrastiveTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    data_collator=collate_fn,\n",
        "    callbacks=[early_stop_callback],\n",
        "    log_cosine_sim=True,\n",
        "    temperature=0.07\n",
        "    # (The Trainer will use AdamW optimizer by default for fine-tuning)\n",
        ")"
      ],
      "metadata": {
        "id": "anOg9WwXXepH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps to get rid of the below error message:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "CUDA out of memory. Tried to allocate 254.00 MiB.\n",
        "GPU 0 has a total capacity of 39.56 GiB of which 48.88 MiB is free.\n",
        "Process 543181 has 39.50 GiB memory in use.\n",
        "Of the allocated memory 38.18 GiB is allocated by PyTorch, and 843.57 MiB is reserved by PyTorch but unallocated.\n",
        "If reserved but unallocated memory is large\n",
        "try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aM-w8p8XpMTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
      ],
      "metadata": {
        "id": "xFENU9CTpovw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Fine-tune the model\n",
        "trainer.can_return_loss = True\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned model and the processor (tokenizer + image processor)\n",
        "trainer.save_model(\"./iu_xray_trainer\")           # Saves the model, config, and projection layers\n",
        "processor.save_pretrained(\"./iu_xray_swin_bert\")  # Saves the image processor and tokenizer for future inference\n",
        "image_processor.save_pretrained(\"./iu_xray_swin\") # Saves the image processor separately"
      ],
      "metadata": {
        "id": "edGYzd3A7uer",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "2af7efa6-f555-4dbc-d2c9-391113907313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='296' max='1480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 296/1480 12:34 < 50:36, 0.39 it/s, Epoch 4/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.075200</td>\n",
              "      <td>1.384834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.069700</td>\n",
              "      <td>1.384835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.069700</td>\n",
              "      <td>1.384835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.071200</td>\n",
              "      <td>1.384835</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./iu_xray_swin/preprocessor_config.json']"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "5zVuW25dJDuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.vision_model.save_pretrained(\"./swin_model\")"
      ],
      "metadata": {
        "id": "G3b_mfGib4Sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoImageProcessor\n",
        "\n",
        "swin_model_after_training = AutoModel.from_pretrained(\"./swin_model\")\n",
        "type(swin_model_after_training)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "o9WuV-0DC1T6",
        "outputId": "b42d46f7-32c4-4dbb-cd38-22e07350dce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.models.swin.modeling_swin.SwinModel"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>transformers.models.swin.modeling_swin.SwinModel</b><br/>def _wrapped_call_impl(*args, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/transformers/models/swin/modeling_swin.py</a>The bare Swin Model transformer outputting raw hidden-states without any specific head on top.\n",
              "This model is a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) sub-class. Use\n",
              "it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage and\n",
              "behavior.\n",
              "\n",
              "Parameters:\n",
              "    config ([`SwinConfig`]): Model configuration class with all the parameters of the model.\n",
              "        Initializing with a config file does not load the weights associated with the model, only the\n",
              "        configuration. Check out the [`~PreTrainedModel.from_pretrained`] method to load the model weights.\n",
              "\n",
              "    add_pooling_layer (`bool`, *optional*, defaults to `True`):\n",
              "            Whether or not to apply pooling layer.\n",
              "    use_mask_token (`bool`, *optional*, defaults to `False`):\n",
              "            Whether or not to create and apply mask tokens in the embedding layer.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 990);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_processor_after_training = AutoImageProcessor.from_pretrained(vision_model_name)\n",
        "\n",
        "# Prepare an input image (e.g., as pixel tensor of shape [1, 3, H, W])\n",
        "image_sample_path = os.path.join(image_paths, train_dataset.texts[0]['image_path'][1])\n",
        "image_sample = Image.open(image_sample_path)\n",
        "inputs_after_training = image_processor_after_training(image_sample, return_tensors=\"pt\")\n",
        "outputs_after_training = swin_model_after_training(**inputs_after_training)\n",
        "last_hidden_state_after_training = outputs_after_training.last_hidden_state"
      ],
      "metadata": {
        "id": "spLU2c3vJ10F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "12d61426fb4747fb9e522d40dccb71da",
            "8a4d0d1fb5c14b0ebb37cf454f1d1295",
            "a6e49a77d68e4f3ab6fbd546b21e6c3e",
            "efe384fd06f64fc09f94f879deb6a2c4",
            "7d6a0c68a5c848b18bbf49e7985f1f14",
            "19f6531d954f413ab44df5930be289a6",
            "d28c8b7780b64834943d830a991bbf58",
            "0df4c20b03d04a959f4c4078a992929e",
            "e531c73ebfa645faa179fd1ff4ce7f68",
            "7bd8dd96df93494eac19ad9d7caf5895",
            "835787c941ae430e8fdb802844aba1ef"
          ]
        },
        "outputId": "eafa8f26-9a64-4d19-b8d9-72ecbabd2dde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/255 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12d61426fb4747fb9e522d40dccb71da"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_hidden_state_after_training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K3JbMEOLOZQ",
        "outputId": "b1e6d38b-8b78-49b3-b402-723eeb33bd76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-2.6363,  0.6361, -0.2943,  ..., -3.5945, -2.5090,  2.2054],\n",
              "         [-0.6450,  0.7285, -1.0084,  ..., -2.3700,  0.6378,  0.2032],\n",
              "         [-1.3251,  0.6057, -0.3762,  ..., -1.6838,  0.9445, -0.1109],\n",
              "         ...,\n",
              "         [-0.5691,  0.1459, -0.2711,  ..., -0.1910, -0.0324, -0.5937],\n",
              "         [-0.6128,  0.0077, -0.2135,  ..., -0.1963, -0.1023, -0.7385],\n",
              "         [ 0.2391, -1.3420, -0.2580,  ..., -0.7011, -1.5491, -1.0209]]],\n",
              "       grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "swin_model_before_training = AutoModel.from_pretrained(vision_model_name)\n",
        "image_processor_before_training = AutoImageProcessor.from_pretrained(vision_model_name)\n",
        "\n",
        "image_sample_path = os.path.join(image_paths, train_dataset.texts[10]['image_path'][1])\n",
        "image_sample = Image.open(image_sample_path)\n",
        "inputs_before_training = image_processor_before_training(image_sample, return_tensors=\"pt\")\n",
        "outputs_before_training = swin_model_before_training(**inputs_before_training)\n",
        "last_hidden_state_before_training = outputs_before_training.last_hidden_state"
      ],
      "metadata": {
        "id": "UBEw44TDLr40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_hidden_state_before_training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m5UPeYR2awm",
        "outputId": "ca94a776-b506-4baa-b54f-26aae0261775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.6885, -0.1341,  0.0371,  ...,  0.5520, -0.4761, -0.1809],\n",
              "         [ 1.6421,  0.4668, -0.7926,  ...,  0.6170, -0.9152,  0.0951],\n",
              "         [-0.5252,  0.1861, -0.0294,  ...,  0.2185,  0.0766, -0.1176],\n",
              "         ...,\n",
              "         [ 0.5667, -0.2789, -0.2853,  ..., -1.1903, -0.7935, -1.4292],\n",
              "         [-0.8639,  0.1013, -0.3427,  ...,  0.2189, -0.4068, -1.1835],\n",
              "         [-0.3088, -0.1537,  0.8109,  ...,  0.2448, -0.7474,  0.1932]]],\n",
              "       grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.all(last_hidden_state_before_training.eq(last_hidden_state_after_training))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMvojjuT2etn",
        "outputId": "5e5e7977-eb66-4fea-be51-69efe71de55a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(False)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    }
  ]
}